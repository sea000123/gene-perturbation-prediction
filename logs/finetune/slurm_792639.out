==========================================
Step 0: Splitting data (30 test genes excluded from train)...
==========================================
Split data already exists, skipping data splitting...
==========================================
Step 1: Converting data to GEARS format...
==========================================
GEARS data already exists, skipping conversion...
==========================================
Step 2: Finetuning scGPT with DDP...
==========================================
Detected 3 GPUs
Using device: cuda:0, Saving to model/scGPT_finetuned
scGPT - INFO - Running on 2025-12-03 01:00:17
scGPT - INFO - Config: {'paths': {'model_dir': 'model/scGPT', 'finetuned_model_dir': 'model/scGPT_finetuned', 'data_dir': 'data/processed', 'test_file': 'test.h5ad', 'train_file': 'train.h5ad', 'output_dir': 'results', 'gears_data_dir': 'data/processed/gears', 'dataset_name': 'vcc'}, 'model': {'pad_token': '<pad>', 'pad_value': 0, 'max_seq_len': 1536, 'include_zero_gene': 'batch-wise', 'embsize': 512, 'd_hid': 512, 'nlayers': 12, 'nhead': 8, 'n_layers_cls': 3, 'dropout': 0.0, 'use_fast_transformer': False}, 'inference': {'batch_size': 16, 'eval_batch_size': 16, 'seed': 42, 'control_target_gene': 'non-targeting'}, 'data': {'special_tokens': ['<pad>', '<cls>', '<eoc>'], 'pert_pad_id': 0}, 'training': {'MLM': True, 'CLS': False, 'CCE': False, 'MVC': False, 'ECS': False, 'amp': True}, 'optimizer': {'lr': 0.0001, 'batch_size': 64, 'eval_batch_size': 64, 'epochs': 15, 'schedule_interval': 1, 'schedule_gamma': 0.9, 'early_stop': 10, 'grad_clip': 1.0}, 'loss': {'type': 'SmoothL1Loss', 'beta': 0.5, 'reduction': 'mean'}, 'load_param_prefixes': ['encoder', 'value_encoder', 'transformer_encoder'], 'split': {'test_genes_file': 'data/raw/test_set.csv', 'train_ratio': 0.833, 'val_ratio': 0.167, 'seed': 42}, 'metrics': {'mae_top_k': 2000}, 'early_stopping': {'metric': 'overall_score'}, 'logging': {'log_interval': 100, 'save_interval': 1}, 'hardware': {'device': 'cuda'}}
scGPT - INFO - Loading data...
here1
here1
scGPT - INFO - Dataset: 18080 genes, 17840 in vocab
scGPT - INFO - Test: 30, Train: 99, Val: 21 perts
here1
scGPT - INFO - Loading pretrained model from model/scGPT/best_model.pt
scGPT - INFO - Model config: embsize=512, nlayers=12, nheads=8
scGPT - INFO - Loading pretrained model from model/scGPT/best_model.pt
scGPT - INFO - Model config: embsize=512, nlayers=12, nheads=8
scGPT - INFO - Train cells: 149364, Val cells: 28977
scGPT - INFO - Loading pretrained model from model/scGPT/best_model.pt
scGPT - INFO - Model config: embsize=512, nlayers=12, nheads=8
scGPT - INFO - Loading parameter encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading parameter encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading parameter value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading parameter encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading parameter value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading parameter encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading parameter value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.in_proj_weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.in_proj_bias with shape torch.Size([1536])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading parameter transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - 
============================================================
Starting training...
============================================================
scGPT - INFO - | epoch   1 | 100/2371 batches | ms/batch 498.40 | loss 0.1820
scGPT - INFO - | epoch   1 | 200/2371 batches | ms/batch 528.88 | loss 0.1544
scGPT - INFO - | epoch   1 | 300/2371 batches | ms/batch 545.18 | loss 0.1439
scGPT - INFO - | epoch   1 | 400/2371 batches | ms/batch 544.29 | loss 0.1418
scGPT - INFO - | epoch   1 | 500/2371 batches | ms/batch 543.43 | loss 0.1428
scGPT - INFO - | epoch   1 | 600/2371 batches | ms/batch 538.44 | loss 0.1425
scGPT - INFO - | epoch   1 | 700/2371 batches | ms/batch 537.25 | loss 0.1429
scGPT - INFO - | epoch   1 | 800/2371 batches | ms/batch 540.47 | loss 0.1417
scGPT - INFO - | epoch   1 | 900/2371 batches | ms/batch 540.70 | loss 0.1404
scGPT - INFO - | epoch   1 | 1000/2371 batches | ms/batch 540.14 | loss 0.1429
scGPT - INFO - | epoch   1 | 1100/2371 batches | ms/batch 545.48 | loss 0.1412
scGPT - INFO - | epoch   1 | 1200/2371 batches | ms/batch 546.18 | loss 0.1418
scGPT - INFO - | epoch   1 | 1300/2371 batches | ms/batch 546.72 | loss 0.1439
scGPT - INFO - | epoch   1 | 1400/2371 batches | ms/batch 546.27 | loss 0.1408
scGPT - INFO - | epoch   1 | 1500/2371 batches | ms/batch 548.28 | loss 0.1433
scGPT - INFO - | epoch   1 | 1600/2371 batches | ms/batch 548.81 | loss 0.1399
scGPT - INFO - | epoch   1 | 1700/2371 batches | ms/batch 546.74 | loss 0.1423
scGPT - INFO - | epoch   1 | 1800/2371 batches | ms/batch 548.87 | loss 0.1402
scGPT - INFO - | epoch   1 | 1900/2371 batches | ms/batch 550.73 | loss 0.1392
scGPT - INFO - | epoch   1 | 2000/2371 batches | ms/batch 550.86 | loss 0.1406
scGPT - INFO - | epoch   1 | 2100/2371 batches | ms/batch 551.79 | loss 0.1409
scGPT - INFO - | epoch   1 | 2200/2371 batches | ms/batch 549.48 | loss 0.1416
scGPT - INFO - | epoch   1 | 2300/2371 batches | ms/batch 548.05 | loss 0.1407
scGPT - INFO - | epoch   1 | time: 3060.95s | loss: 3.2356 | PDS: 0.4722 | DES: 0.1876 | MAE: 1.2428
scGPT - INFO -   overall_score: 5.00
scGPT - INFO -   -> New best (overall_score=5.00)
scGPT - INFO - | epoch   2 | 100/2371 batches | ms/batch 551.22 | loss 0.1391
scGPT - INFO - | epoch   2 | 200/2371 batches | ms/batch 555.93 | loss 0.1404
scGPT - INFO - | epoch   2 | 300/2371 batches | ms/batch 556.05 | loss 0.1401
scGPT - INFO - | epoch   2 | 400/2371 batches | ms/batch 558.01 | loss 0.1388
scGPT - INFO - | epoch   2 | 500/2371 batches | ms/batch 551.57 | loss 0.1421
scGPT - INFO - | epoch   2 | 600/2371 batches | ms/batch 556.21 | loss 0.1410
scGPT - INFO - | epoch   2 | 700/2371 batches | ms/batch 549.78 | loss 0.1399
scGPT - INFO - | epoch   2 | 800/2371 batches | ms/batch 552.56 | loss 0.1386
scGPT - INFO - | epoch   2 | 900/2371 batches | ms/batch 550.16 | loss 0.1417
scGPT - INFO - | epoch   2 | 1000/2371 batches | ms/batch 554.20 | loss 0.1406
scGPT - INFO - | epoch   2 | 1100/2371 batches | ms/batch 553.40 | loss 0.1396
scGPT - INFO - | epoch   2 | 1200/2371 batches | ms/batch 552.99 | loss 0.1391
scGPT - INFO - | epoch   2 | 1300/2371 batches | ms/batch 554.79 | loss 0.1377
scGPT - INFO - | epoch   2 | 1400/2371 batches | ms/batch 549.00 | loss 0.1397
scGPT - INFO - | epoch   2 | 1500/2371 batches | ms/batch 552.32 | loss 0.1398
scGPT - INFO - | epoch   2 | 1600/2371 batches | ms/batch 553.18 | loss 0.1383
scGPT - INFO - | epoch   2 | 1700/2371 batches | ms/batch 551.76 | loss 0.1386
scGPT - INFO - | epoch   2 | 1800/2371 batches | ms/batch 553.59 | loss 0.1380
scGPT - INFO - | epoch   2 | 1900/2371 batches | ms/batch 553.04 | loss 0.1366
scGPT - INFO - | epoch   2 | 2000/2371 batches | ms/batch 552.58 | loss 0.1423
scGPT - INFO - | epoch   2 | 2100/2371 batches | ms/batch 550.71 | loss 0.1392
scGPT - INFO - | epoch   2 | 2200/2371 batches | ms/batch 552.40 | loss 0.1394
scGPT - INFO - | epoch   2 | 2300/2371 batches | ms/batch 551.32 | loss 0.1409
